# Pull Request
**PR** es una solicitud para fusionar cambios de c√≥digo en un repositorio de control de versiones. Su prop√≥sito es permitir que otros miembros del equipo revisen y aprueben los cambios antes de integrarlos en la rama principal del proyecto.

**Ejemplo**
Supongamos que est√°s trabajando en una nueva configuraci√≥n de infraestructura usando **Terraform**. Creas una nueva rama en tu repositorio:
```sh
git checkout -b nueva-configuracion
```

Haces cambios en los archivos de configuraci√≥n y los subes al repositorio
```sh
git add .
git commit -m "Agregada configuraci√≥n para balanceador de carga"
git push origin nueva-configuracion
```

Luego, en GitHub, creas un **Pull Request** para que tu equipo revise los cambios antes de fusionarlos en la rama principal.

# Entorno preproductivo

Un **entorno preproductivo** es un entorno de pruebas que simula la infraestructura de producci√≥n pero sin afectar a los usuarios finales. Se utiliza para validar cambios antes de su despliegue final.

**Ejemplo de entorno preproductivo**

Si tienes una aplicaci√≥n web, podr√≠as tener tres entornos distintos:

- **Desarrollo (dev):** Aqu√≠ los programadores prueban nuevas funcionalidades.
- **Preproducci√≥n (staging):** Simula el entorno real y permite probar cambios antes de que los usuarios los vean.
- **Producci√≥n (prod):** Donde los usuarios acceden a la aplicaci√≥n real.

Cuando usas IaC, puedes desplegar una infraestructura id√©ntica en un entorno preproductivo para validar cambios antes de implementarlos en producci√≥n.


# Linting

El **linting** es el proceso de analizar c√≥digo para detectar errores de sintaxis, estilos inconsistentes y malas pr√°cticas.

#### **Ejemplo de linting en Ansible con `ansible-lint`:**

Si tienes un `playbook.yml` mal escrito:

```yaml
- hosts: all
  tasks:
    - name: Instalar nginx
      apt:
       name: nginx
       state: present

```

Ejecutar 
```sh
ansible-lint playbook.yml
```
detectar√° errores como mala indentaci√≥n y sugerir√° correcciones.

Otros ejemplos de herramientas de linting:

- `terraform validate` (para Terraform)
- `pylint` (para Python)
- `eslint` (para JavaScript)

# HashiCorp Vault

**HashiCorp Vault** es una herramienta dise√±ada para **almacenar, gestionar y proteger secretos y credenciales** de manera segura.

Un "secreto" en este contexto puede ser:
- Contrase√±as
- Claves API
- Tokens de acceso
- Credenciales de bases de datos

Muchas aplicaciones almacenan secretos en **archivos de configuraci√≥n en texto plano**, lo cual es un grave riesgo de seguridad.  
Con **Vault**, los secretos se almacenan en una base de datos cifrada, con **control de acceso** y **auditor√≠a**.

### Principales caracter√≠sticas de HashiCorp Vault


**1. Almacenamiento seguro de secretos**
Vault **cifra** autom√°ticamente los secretos antes de almacenarlos en su backend de datos.
Podemos almacenar una clave API de manera segura en Vault con el siguiente comando:
```sh
vault kv put secret/api-key value="1234567890"
```

Esto almacena `1234567890` bajo la clave `api-key` en la ruta `secret/`. Para recuperarla:
```sh
vault kv get secret/api-key
```

Salida esperada:
```
Key       Value
---       -----
value     1234567890
```

Esto evita que las claves API queden expuestas en archivos de configuraci√≥n.

**2. Acceso basado en permisos (ACLs)**
Vault permite definir **pol√≠ticas de acceso**.  
Por ejemplo, podr√≠amos dar acceso de solo lectura a un servicio espec√≠fico:

```hcl
path "secret/api-key" {
  capabilities = ["read"]
}
```

As√≠, solo ciertos usuarios o aplicaciones pueden acceder a los secretos.

**3. Expiraci√≥n y renovaci√≥n de credenciales**
Vault puede **generar credenciales temporales** que se eliminan despu√©s de un tiempo.  
Ejemplo:  
Un usuario solicita credenciales para una base de datos MySQL:

```sh
vault read database/creds/read-only
```
Vault devuelve credenciales temporales, que expiran autom√°ticamente despu√©s de cierto tiempo, reduciendo riesgos.

**4. Autenticaci√≥n flexible**
Vault permite autenticarse con varios m√©todos:

- Tokens (`vault login -method=token`) 
- GitHub OAuth
- AWS IAM
- Kubernetes Service Accounts

Esto facilita la integraci√≥n con aplicaciones y servicios en la nube.


# Vagrant
**Vagrant** es una herramienta de c√≥digo abierto que permite crear, configurar y gestionar m√°quinas virtuales de manera automatizada, usando un archivo de configuraci√≥n llamado `Vagrantfile`

**Ventajas**
- Creaci√≥n r√°pida de entornos de desarrollo.
- Facilita la colaboraci√≥n al definir entornos id√©nticos.
- Compatible con VirtualBox, VMware, Hyper-V, entre otros.
- Permite ejecutar scripts de aprovisionamiento autom√°ticamente

>[!Note] Entorno de desarrollo
>Conjunto de herramientas, configuraciones y software que permiten a los programadores escribir, probar y ejecutar c√≥digo en un ambiente controlado antes de desplegarlo en producci√≥n. Tambi√©n existe entorno de pruebas o testing y preproducci√≥n o staging.

Verificar instalaci√≥n
```bash
vagrant --version
```

## Vagrantfile
Es un archivo de configuraci√≥n en **Ruby** que define la infraestructura de la m√°quina virtual.
```ruby
Vagrant.configure("2") do |config|
	config.vm.box = "ubuntu/bionic64"
```


**Comandos b√°sicos**
```bash
# Inicia la m√°quina virtual
vagrant up

# Apaga la m√°quina virtual
vagrant halt

# Elimina la m√°quina virtual
vagrant destroy

# Muestra el estado actual de la m√°quina virtual
vagran status
```


### Configuraci√≥n Avanzada del Vagrantfile

El **Vagrantfile** permite configurar m√°quinas virtuales con opciones m√°s avanzadas para mejorar el rendimiento, la seguridad y la automatizaci√≥n del entorno de desarrollo. Aqu√≠ veremos varias configuraciones clave:

#### Personalizaci√≥n de Recursos (CPU, RAM, VirtualBox)

Puedes ajustar la cantidad de CPU y RAM asignada a la m√°quina virtual para optimizar el rendimiento. Esto es √∫til si tu proyecto requiere m√°s recursos.

#### Configuraci√≥n de Redes (Red Privada, P√∫blica y NAT)

- **Red privada:** Permite la comunicaci√≥n entre la m√°quina anfitriona y la m√°quina virtual sin exponerla a Internet.
- **Red p√∫blica:** Hace que la m√°quina sea accesible desde la red local.
- **NAT (Network Address Translation):** La m√°quina virtual se conecta a Internet usando la red del anfitri√≥n.


#### Sincronizaci√≥n de Carpetas entre Host y M√°quina Virtual
Esto permite compartir archivos entre el sistema operativo anfitri√≥n y la m√°quina virtual.

#### Aprovisionamiento Autom√°tico con Shell y Ansible
Vagrant permite ejecutar scripts para configurar autom√°ticamente la m√°quina virtual despu√©s de su creaci√≥n.

#### Ejemplos

**Configurar CPU, RAM y VirtualBox en Vagrantfile**
Este c√≥digo ajusta la memoria RAM a **2 GB** y asigna **2 n√∫cleos de CPU** a la m√°quina virtual.

```ruby
Vagrant.configure("2") do |config|

  # Usar la imagen base de Ubuntu 20.04
  config.vm.box = "ubuntu/focal64"

  # Configurar recursos de la m√°quina virtual en VirtualBox
  config.vm.provider "virtualbox" do |vb|
    vb.memory = "2048"   # 2 GB de RAM
    vb.cpus = 2          # 2 N√∫cleos de CPU
  end

end
```

üìå **¬øPara qu√© sirve esto?**

- Se asegura de que la m√°quina virtual tenga suficiente RAM y CPU para correr aplicaciones sin ralentizarse.
    

---

**Configurar Redes en Vagrantfile**

```ruby
Vagrant.configure("2") do |config|

  # Usar la imagen de Ubuntu 22.04
  config.vm.box = "ubuntu/jammy64"

  # Configuraci√≥n de red privada (IP est√°tica)
  config.vm.network "private_network", ip: "192.168.33.10"

  # Configuraci√≥n de red p√∫blica (Se asigna IP autom√°ticamente)
  config.vm.network "public_network"

end
```


- Permite que los servicios dentro de la VM sean accesibles desde la m√°quina anfitriona.
- √ötil para simular entornos de producci√≥n sin exponerlos a Internet.

**Sincronizaci√≥n de Carpetas**

```ruby
Vagrant.configure("2") do |config|

  # Definir la imagen base
  config.vm.box = "ubuntu/focal64"

  # Configurar carpeta compartida entre host y VM
  config.vm.synced_folder "./proyecto", "/var/www/proyecto"

end
```


- Facilita el desarrollo porque los archivos creados en el host se reflejan en la VM sin necesidad de transferencias manuales.

**Aprovisionamiento con Script de Shell**

```ruby
Vagrant.configure("2") do |config|

  # Definir la imagen base
  config.vm.box = "ubuntu/bionic64"

  # Aprovisionamiento con script de Shell
  config.vm.provision "shell", inline: <<-SHELL
    sudo apt-get update                # Actualizar lista de paquetes
    sudo apt-get install -y apache2    # Instalar servidor Apache
    echo "Servidor Apache listo" > /var/www/html/index.html  # Crear p√°gina web
  SHELL

end
```

- Automatiza la instalaci√≥n de paquetes en la VM sin necesidad de hacerlo manualmente.

**Aprovisionamiento con Ansible**
Si prefieres usar **Ansible** en lugar de un script de shell, puedes integrarlo con Vagrant.

```ruby
Vagrant.configure("2") do |config|

  # Usar una imagen de Ubuntu 22.04
  config.vm.box = "ubuntu/jammy64"

  # Configurar Ansible para instalar y configurar Nginx
  config.vm.provision "ansible" do |ansible|
    ansible.playbook = "playbook.yml"  # Archivo de configuraci√≥n de Ansible
  end

end
```
Permite definir configuraciones m√°s complejas y reutilizables usando Ansible.

## Comandos √∫tiles de Vagrant


| Comando           | Descripci√≥n                                    |
| ----------------- | ---------------------------------------------- |
| `vagrant init`    | crea un `Vagrantfile` inicial.                 |
| `vagrant up`      | Inicia la VM                                   |
| `vagran halt`     | Apaga la VM                                    |
| `vagrant destroy` | Borra la VM                                    |
| `vagrant ssh`     | Accede a la VM por ssh                         |
| `vagrant reload`  | Reinicia la VM con cambios en el `Vagrantfile` |


# Aprovisionamiento
Se refiere al proceso de configurar y suministrar los recursos necesarios para que un sistema o aplicaci√≥n funcione correctamente. En el contexto de infraestructura de TI, significa la asignaci√≥n y configuraci√≥n de servidores, redes, almacenamiento y otros recursos ya sea de forma manual o automatizada.

# Pipeline
Es un flujo de trabajo automatizado que define una serie de pasos secuenciales para procesar y transformar datos o c√≥digo. En **DevOps** y **CI/CD**, un pipeline se usa para automatizar la construcci√≥n, prueba y despliegue de aplicaciones.

# Esc√°neres de vulnerabilidades
Son herramientas automatizadas que analizan el c√≥digo, las dependencias y los contenedores para identificar riesgos de seguridad conocidos.

Herramientas comunes
- **Trivy**
- **Anchore**
- **Snyk**
- **Clair**

¬øQue buscan estos esc√°neres?
- **Dependencias inseguras**
- **Malas configuraciones**
- **Errores en contenedores**

# An√°lisis de c√≥digo (SAST y DAST)
El **an√°lisis de c√≥digo** se divide en dos categor√≠as principales:

**An√°lisis est√°tico de c√≥digo (SAST - Static Application Security Testing)**
Se usa para detectar problemas temprano en el desarrollo.
- Se ejecuta antes de ejecutar la aplicaci√≥n.
- Examina el c√≥digo fuente en busca de patrones inseguros, fallos de validaci√≥n, inyecciones SQL, etc.
- No requiere ejecutar la aplicaci√≥n.



**An√°lisis din√°mico de c√≥digo (DAST - Dynamic Application Security Testing)**
- Se ejecuta **mientras la aplicaci√≥n est√° en ejecuci√≥n**
- Detecta vulnerabilidades en **tiempo de ejecuci√≥n**, como ataques de inyecci√≥n o errores de permisos.
- Se usa para probar APIs y aplicaciones web.


# logs
Los **logs** (registros de eventos) son archivos o mensajes generados autom√°ticamente por sistemas operativos, aplicaciones, servidores, bases de datos y dispositivos de red. Estos registros documentan eventos importantes, como errores, accesos de usuarios, cambios en la configuraci√≥n y actividad del sistema.

Los logs son esenciales para:
1. **Monitoreo del sistema**
2. **Depuraci√≥n y resoluci√≥n de errores**
3. **Seguridad y auditor√≠a**
4. **Optimizaci√≥n del rendimiento**


# Troubleshooting
Es el proceso sistem√°tica de identificar, analizar y resolver problemas en sistemas de software, hardware, redes u otros entornos tecnol√≥gicos.

El troubleshooting sigue un enfoque estructurado para detectar y corregir errores, generalmente en estos pasos:
1. **Identificaci√≥n del problema**
2. **Hip√≥tesis y diagn√≥stico**
3. **Prueba de soluciones**
4. **Documentaci√≥n y prevenci√≥n**


# üîÑ **Flujo de trabajo en DevSecOps y herramientas asociadas**

1Ô∏è‚É£ **Infraestructura como C√≥digo (IaC)**

- **Terraform**: Se usa para definir y aprovisionar infraestructura en la nube (AWS, Azure, GCP) mediante c√≥digo declarativo.
- **Vagrant**: Permite crear y configurar entornos virtuales localmente, √∫til para desarrollo y pruebas.


2Ô∏è‚É£ **Configuraci√≥n y Automatizaci√≥n**

- **Ansible**: Automatiza la configuraci√≥n de servidores y la instalaci√≥n de software. Se usa despu√©s de Terraform para preparar el entorno.


3Ô∏è‚É£ **Contenedores y Orquestaci√≥n**

- **Docker**: Permite empaquetar aplicaciones y sus dependencias en contenedores, facilitando su despliegue en diferentes entornos.
- **Kubernetes**: Orquesta y gestiona m√∫ltiples contenedores en un cl√∫ster, asegurando escalabilidad y alta disponibilidad.
    

4Ô∏è‚É£ **Monitoreo y Observabilidad**

- **Prometheus**: Recopila m√©tricas de sistemas y aplicaciones en tiempo real para detectar problemas.
- **Grafana**: Se usa para visualizar datos de Prometheus y generar paneles de monitoreo.

---

### üìå **Relaci√≥n entre herramientas y c√≥mo trabajan juntas**

1. **Terraform** crea la infraestructura necesaria en la nube.
2. **Ansible** configura los servidores y despliega software.
3. **Docker** empaqueta las aplicaciones en contenedores.
4. **Kubernetes** gestiona y escala estos contenedores en producci√≥n.
5. **Prometheus** recopila m√©tricas del sistema y **Grafana** las visualiza.


# Proyecto DevSecOps: Implementaci√≥n de una Aplicaci√≥n Web con Infraestructura como C√≥digo

Este proyecto tiene como objetivo desplegar una aplicaci√≥n web utilizando herramientas de **DevSecOps**, incluyendo **Terraform, Ansible, Docker, Kubernetes, Prometheus y Grafana**. Se explica el flujo de trabajo paso a paso con comentarios detallados en el c√≥digo y una explicaci√≥n adicional en cada secci√≥n.

---

## **1. Provisionamiento de Infraestructura con Terraform**

Terraform se usa para crear una instancia en AWS donde desplegaremos la aplicaci√≥n.

### **Archivo: `main.tf`**

```hcl
# Especificamos el proveedor de cloud, en este caso AWS
provider "aws" {
  region = "us-east-1" # Define la regi√≥n en la que se crear√° la instancia
}

# Creaci√≥n de una instancia EC2 en AWS
resource "aws_instance" "devsecops_server" {
  ami           = "ami-0c55b159cbfafe1f0" # ID de una imagen Ubuntu
  instance_type = "t2.micro"  # Tipo de instancia (gratuita en AWS)

  tags = {
    Name = "DevSecOps-Instance" # Etiqueta de la instancia para identificarla
  }
}
```

### **Explicaci√≥n**

1. Se declara AWS como proveedor de infraestructura.
    
2. Se define una m√°quina virtual con Ubuntu en la regi√≥n `us-east-1`.
    
3. Se etiqueta la instancia con el nombre `DevSecOps-Instance`.
    

Ejecutar los siguientes comandos para aplicar la configuraci√≥n:

```bash
terraform init  # Inicializa el proyecto Terraform
terraform apply -auto-approve  # Crea la infraestructura
```

---

## **2. Configuraci√≥n del Servidor con Ansible**

Ansible se usa para instalar Docker y Kubernetes en la instancia creada.

### **Archivo: `playbook.yml`**

```yaml
- name: Configurar Servidor para DevSecOps
  hosts: all
  become: yes  # Ejecuta comandos como superusuario (root)
  tasks:
    - name: Instalar Docker y Kubernetes
      apt:
        name: "{{ item }}"
        state: present
      with_items:
        - docker.io
        - kubectl
```

### **Explicaci√≥n**

1. Se define un "playbook" de Ansible para configurar el servidor.
    
2. Se ejecuta en todos los hosts especificados en el inventario.
    
3. Se instalan Docker y Kubernetes con el gestor de paquetes `apt`.
    

Ejecutar:

```bash
ansible-playbook -i inventory playbook.yml
```

---

## **3. Creaci√≥n de una Imagen Docker con la Aplicaci√≥n Web**

Se empaqueta una aplicaci√≥n Flask dentro de un contenedor Docker.

### **Archivo: `Dockerfile`**

```dockerfile
# Imagen base con Python 3.8
FROM python:3.8

# Define el directorio de trabajo dentro del contenedor
WORKDIR /app

# Copia el c√≥digo de la aplicaci√≥n al contenedor
COPY app.py .

# Instala Flask dentro del contenedor
RUN pip install flask

# Ejecuta la aplicaci√≥n cuando el contenedor inicie
CMD ["python", "app.py"]
```

### **Archivo: `app.py`**

```python
from flask import Flask
app = Flask(__name__)

@app.route("/")
def home():
    return "\u00a1Aplicaci√≥n en Kubernetes con DevSecOps!"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

Ejecutar:

```bash
docker build -t myapp .
docker run -d -p 5000:5000 myapp
```

---

## **4. Orquestaci√≥n con Kubernetes**

Se define un `Deployment` y un `Service` en Kubernetes.

### **Archivo: `deployment.yaml`**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myapp:latest
        ports:
        - containerPort: 5000
---
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  selector:
    app: myapp
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000
  type: LoadBalancer
```

Ejecutar:

```bash
kubectl apply -f deployment.yaml
```

---

## **5. Monitoreo con Prometheus y Grafana**

### **Archivo: `prometheus.yaml`**

```yaml
global:
  scrape_interval: 15s
scrape_configs:
  - job_name: 'kubernetes'
    static_configs:
      - targets: ['localhost:9090']
```

Ejecutar:

```bash
kubectl apply -f prometheus.yaml
kubectl create deployment grafana --image=grafana/grafana
kubectl expose deployment grafana --type=LoadBalancer --port=3000
```

---

## **Resumen del Flujo DevSecOps**

1. **Terraform** crea la infraestructura en AWS.
2. **Ansible** instala Docker y Kubernetes.
3. **Docker** empaqueta la aplicaci√≥n en contenedores.
4. **Kubernetes** orquesta la aplicaci√≥n en un cl√∫ster.
5. **Prometheus y Grafana** permiten el monitoreo y visualizaci√≥n de m√©tricas.

Este proyecto te permite practicar un flujo completo de **DevSecOps** con herramientas modernas. üöÄ


# Delta Compression
En Git, se usa en los **objetos pack** (`packfiles`) para optimizar el almacenamiento y transmisi√≥n de datos. En lugar de almacenar versiones completas de archivos, Git almacena las diferencias (deltas) entre versiones anteriores y posteriores, reduciendo el tama√±o del repositorio.

> **Ejemplo**: Si tienes un archivo que ha cambiado ligeramente en varias confirmaciones (`commits`), Git puede almacenar solo las diferencias en lugar de varias copias completas.


# Blob (Binary Large Object)
- Un blob en Git representa el contenido binario de un archivo. Es el objeto m√°s b√°sico en Git y almacena √∫nicamente los datos del archivo, sin informaci√≥n sobre su nombre o ubicaci√≥n en el sistema de archivos.
- Cada blob se identifica mediante un hash **SHA-1**, que se genera a partir del contenido del archivo.

---
 **Ejemplo**: Imagina que tienes un archivo `index.html`
```
> <html>
> 	<head>
> 	</head>
> 	<body>
> 		<h1>Hola mundo</h1>
> 	</body>
> </html>
```

Cuando se ejecuta `git add index.html`, Git crea un blob para almacenar este contenido. Si cambias el archivo Git generar√° un nuevo blob para representar el nuevo contenido.

>[!note] Si el contenido de un archivo no cambia entre commits Git reutiliza el mismo blob en lugar de crear uno nuevo.



# Tree (Git)
- Act√∫a como un directorio virtual. Asocia blobs con sus nombres de archivo, rutas y permisos, permitiendo a Git organizar los archivos dentro de una estructura jer√°rquica.
- Cada tree contiene referencias a blobs (para archivos) y otros trees (para subdirectorios).

---
**Ejemplo**

Supongamos que tienes el proyecto
```
proyecto/
‚îú‚îÄ‚îÄ index.html
‚îú‚îÄ‚îÄ style.css

```
Cuando haces un commit, Git crea un tree que incluye referencias a los blobs correspondientes a `index.html` y `style.css`. Este tree almacena informaci√≥n como:
- Permisos de archivo
- Nombre del archivo
- Hash del blob asociado.
Si agregas una subcarpeta llamada `img/` Git creara otro tree para esa carpeta y lo referenciara desde el tree principal.


# Tag (Git)
En Git, un tag es una referencia que apunta a un commit espec√≠fico en el historial del proyecto, Los tags se utilizan com√∫nmente para marcar versiones importantes del proyecto, como lanzamientos o releases. Hay dos tipos: **lightweight** (sin metadatos adicionales) y **annotated** (con metadatos como autor y fecha).


# C√≥digo de Prop√≥sito √önico

El *c√≥digo de prop√≥sito √∫nico* se refiere a un principio de dise√±o en el desarrollo de software donde cada componente o fragmento de c√≥digo tiene una √∫nica responsabilidad o funci√≥n espec√≠fica. Este enfoque promueve la claridad, modularidad y facilidad de mantenimiento en el c√≥digo fuente. Se alinea con las mejores pr√°cticas de desarrollo √°gil y DevOps al facilitar la adaptabilidad y la integraci√≥n continua.

**Caracter√≠sticas principales:**
- **Responsabilidad √∫nica:** Cada componente realiza una tarea espec√≠fica, evitando sobrecargas funcionales.
- **Modularidad:** Los componentes son independientes entre s√≠, lo que facilita su comprensi√≥n, modificaci√≥n y prueba.
- **Facilidad en CI/CD:** La integraci√≥n continua (CI) y el despliegue continuo (CD) son m√°s eficientes porque los m√≥dulos independientes reducen las probabilidades de conflictos o errores inesperados durante las integraciones.

**Beneficios:**
1. **Depuraci√≥n eficiente:** Es m√°s sencillo identificar problemas en componentes con responsabilidades claras.
2. **Colaboraci√≥n simplificada:** Los cambios en Git son m√°s comprensibles, lo que mejora la revisi√≥n de c√≥digo y la comunicaci√≥n entre desarrolladores.
3. **Adaptabilidad:** Los componentes pueden ser modificados o reemplazados sin afectar significativamente otros m√≥dulos.

---

# C√≥digo Completo

El *c√≥digo completo* es un principio que enfatiza que cualquier fragmento de c√≥digo desarrollado debe estar terminado en t√©rminos de intenci√≥n y ejecuci√≥n antes de ser integrado al sistema. Esto implica que el c√≥digo cumpla con su prop√≥sito espec√≠fico, sea apto para revisi√≥n por pares y est√© respaldado por pruebas adecuadas.

**Caracter√≠sticas principales:**
- **Integridad funcional:** El c√≥digo debe cumplir completamente con los requisitos establecidos para su funci√≥n.
- **Preparaci√≥n para revisi√≥n:** Debe adherirse a los est√°ndares del equipo o proyecto.
- **Pruebas incluidas:** El c√≥digo debe estar acompa√±ado por pruebas que validen su funcionamiento.

**Beneficios:**
1. **Calidad asegurada:** Garantiza que el c√≥digo integrado no cause interrupciones ni problemas en los pipelines de CI/CD.
2. **Colaboraci√≥n eficiente:** Facilita revisiones m√°s profundas y productivas al eliminar problemas b√°sicos antes de la integraci√≥n.
3. **Iteraci√≥n progresiva:** Aunque no busca la perfecci√≥n inicial, fomenta mejoras continuas basadas en retroalimentaci√≥n.

**Relaci√≥n con DevOps:**
En entornos DevOps, el c√≥digo completo es esencial para mantener flujos √°giles y eficientes en CI/CD, asegurando que el software entregado sea funcional y confiable.



# Balanceadores de carga
Un **balanceador de carga** (load balancer) es un componente que distribuye el tr√°fico de red o de solicitudes entre varios servidores. Su prop√≥sito es:

- üîÑ Evitar que un solo servidor se sobrecargue.
- ‚ö° Mejorar el rendimiento.
- üõ°Ô∏è Aumentar la disponibilidad y tolerancia a fallos.
- üìà Escalar aplicaciones f√°cilmente.

> [!tip] Ejemplo
> Imagina que tienes una aplicaci√≥n web que recibe 1000 usuarios por segundo. Si solo tienes un servidor, puede colapsar. Pero si tienes 3 servidores, un balanceador de carga puede enviar ~333 usuarios a cada uno, manteni√©ndolo equilibrado.

[Qu√© es un balanceador de carga y c√≥mo mejora el rendimiento de la web](https://www.redeszone.net/tutoriales/servidores/balanceador-carga-load-balancer-que-es-funcionamiento/)

### ¬øC√≥mo funciona el balanceador de carga?

Cuando un usuario accede a un sitio web, el balanceador de carga recibe la solicitud y decide a qu√© servidor enviarla. Utiliza diferentes algoritmos para determinar la distribuci√≥n m√°s eficiente de las solicitudes, teniendo en cuenta factores como la capacidad de procesamiento de cada servidor, la carga actual y la disponibilidad.

Existen varios tipos de balanceadores de carga, como los balanceadores de carga basados en hardware, que son dispositivos f√≠sicos dedicados, y los balanceadores de carga basados en software, que se ejecutan en servidores virtuales. Independientemente del tipo, el balanceador de carga realiza las siguientes funciones:

- **Recepci√≥n de solicitudes:**¬†El balanceador de carga act√∫a como punto de entrada para las solicitudes de los usuarios. Recibe las peticiones y las redirige a los servidores disponibles.
- **Distribuci√≥n de carga:**¬†Utilizando algoritmos de balanceo, el balanceador de carga decide a qu√© servidor enviar cada solicitud. Los algoritmos m√°s comunes son el Round Robin, donde se asigna secuencialmente cada solicitud a un servidor, y el Least Connections, que env√≠a las solicitudes al servidor con la menor carga actual.
- **Monitorizaci√≥n de servidores:**¬†El balanceador de carga supervisa constantemente el estado de los servidores. Si detecta que un servidor no responde o est√° sobrecargado, lo excluye temporalmente de la distribuci√≥n de carga para evitar interrupciones en el servicio.
- **Tolerancia a fallos:**¬†En caso de que un servidor falle, el balanceador de carga redirige autom√°ticamente las solicitudes a los servidores restantes. Esto asegura que el sitio web siga funcionando sin interrupciones, minimizando el impacto de cualquier problema en un servidor individual.
- **Escalabilidad:**¬†A medida que la carga de trabajo aumenta, es posible agregar nuevos servidores al grupo y configurar el balanceador de carga para que distribuya la carga de manera equitativa entre ellos. Esto permite escalar horizontalmente el sistema, aumentando la capacidad de procesamiento seg√∫n sea necesario.
- **Sesiones persistentes:**¬†En algunos casos, es necesario mantener la conexi√≥n del usuario con el mismo servidor durante toda su sesi√≥n. El balanceador de carga puede configurarse para asignar una sesi√≥n persistente a un servidor espec√≠fico, asegurando la continuidad de la experiencia del usuario.

Por tanto, hay que tener claro que son varias las funcionalidades que debe cumplir con el objetivo de que se pueda dar un servicio de garant√≠a a los servidores web de diferentes p√°ginas.




---

# ‚ö° `uvicorn`

**¬øQu√© es?**  
Uvicorn es un **servidor ASGI** (Asynchronous Server Gateway Interface). Es el que realmente ejecuta tu aplicaci√≥n FastAPI y maneja las conexiones HTTP de forma as√≠ncrona.

**En resumen**: Es como el "motor" que arranca tu aplicaci√≥n y recibe las peticiones de los usuarios.

üõ†Ô∏è Comando t√≠pico para correr tu app:

```bash
uvicorn main:app --reload
```

(`main` es el nombre del archivo Python, y `app` es la instancia de FastAPI)

---

# üßµ `asyncpg`

**¬øQu√© es?**  
Es un **driver as√≠ncrono** para conectarse a **PostgreSQL** desde Python. Es muy r√°pido y permite hacer consultas a la base de datos sin bloquear el servidor.

**¬øPor qu√© no usar psycopg2?**  
Porque `psycopg2` es s√≠ncrono. Si est√°s trabajando con `async`/`await`, `asyncpg` es una mejor opci√≥n.

---

# üõ¢Ô∏è `databases`

**¬øQu√© es?**  
Es una librer√≠a que sirve como **capa intermedia** para conectarse a bases de datos de forma as√≠ncrona. Funciona con `asyncpg`, pero te da una interfaz m√°s f√°cil para hacer queries, y adem√°s permite cambiar de motor f√°cilmente (por ejemplo, de PostgreSQL a SQLite o MySQL).

**Ejemplo de uso con FastAPI y asyncpg:**

```python
from databases import Database

database = Database("postgresql://user:password@localhost/dbname")
await database.connect()
```



# S√≠ncrono y as√≠ncrono
### üéØ Concepto b√°sico

#### ‚úÖ **S√≠ncrono**:

- Las tareas se ejecutan **una a la vez**, en **orden**.
    
- Cada operaci√≥n **bloquea** el programa hasta que termina.
    

üì¶ Ejemplo:

```python
def fetch_data():
    data = slow_database_call()  # esto puede tardar varios segundos
    print("Datos obtenidos:", data)
```

‚û°Ô∏è Si `slow_database_call()` tarda 3 segundos, el programa **espera esos 3 segundos sin hacer nada m√°s**.

---

#### ‚ö° **As√≠ncrono**:

- Las tareas **no bloquean** el flujo del programa.
    
- Usa `async` y `await` para decirle a Python: "esto puede tardar, pero mientras tanto puedes hacer otras cosas".
    

üì¶ Ejemplo:

```python
async def fetch_data():
    data = await slow_database_call()
    print("Datos obtenidos:", data)
```

‚û°Ô∏è Mientras espera a que `slow_database_call()` termine, Python puede manejar otras tareas (como responder a otras peticiones HTTP).

---

### üß† ¬øPor qu√© importa en desarrollo web?

Imagina que tienes una API que recibe muchas peticiones al mismo tiempo:

#### Con un enfoque **s√≠ncrono**:

- Cada petici√≥n **espera su turno**.
    
- Si una toma mucho tiempo (como una consulta a la base de datos o a una API externa), **las dem√°s se quedan esperando**.
    

#### Con un enfoque **as√≠ncrono**:

- Puedes **atender m√∫ltiples peticiones al mismo tiempo**, incluso si algunas est√°n esperando datos.
    
- Mejora **el rendimiento**, **la escalabilidad** y el **uso eficiente de recursos**.
    

---

### üèéÔ∏è Ejemplo visual

Imagina que est√°s en una cafeter√≠a:

- **S√≠ncrono**: el barista solo atiende a un cliente a la vez. Si uno pide algo que tarda, los dem√°s esperan.
    
- **As√≠ncrono**: el barista toma varios pedidos, pone a calentar el caf√© de uno, sirve el t√© de otro mientras tanto, y va avanzando en paralelo.
    

---

### üîß En resumen:

|Caracter√≠stica|S√≠ncrono|As√≠ncrono|
|---|---|---|
|Ejecuci√≥n|Una cosa a la vez|Muchas tareas "en paralelo" (no bloqueantes)|
|Recursos|Usa m√°s CPU/RAM para muchas conexiones|M√°s eficiente con menos recursos|
|Ideal para|Scripts simples, tareas peque√±as|APIs, servicios con muchas conexiones concurrentes|

---




# Caching
Guarda artefactos o dependencias ya procesadas (como librer√≠as o resultados de compilaci√≥n) para evitar trabajos repetitivos en ejecuciones futuras del pipeline. 

# Matrices de entorno
Permiten ejecutar el mismo job de pruebas sobre distintas combinaciones de entornos (versiones de lenguajes, sistemas operativos, etc.)

*Ejemplo*: probar una app de Python en Ubuntu con Python 3.8, 3.9 y 3.10 simult√°neamente.


