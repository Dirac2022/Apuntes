
## Resumen

Una red de entrega de contenido (CDN Content Delivery Network) es una infraestructura distribuida para entregar contenido digital a usuarios finales con alto rendimiento. Las CDN son críticas para proporcionar y proteger la disponibilidad de contenidos en Internet. Sin embargo, los adversarios no solo pueden evadir la protección de la CDN, sino también usar los recursos de la CDN para lanzar ataques más sofisticados.

En este artículo, proporcionamos la primera encuesta sobre seguridad de CDN. Categorizamos los desafíos de seguridad de CDN según los componentes de la infraestructura de CDN, discutimos posibles contramedidas y su efectividad, y delineamos direcciones futuras de investigación. Este documento tiene como objetivo resaltar el estado de la seguridad de CDN e identificar importantes desafíos de investigación en esta área.

# I. INTRODUCCIÓN
Una red de entrega de contenido (CDN) consta de servidores distribuidos geográficamente para almacenar en caché y entregar eficientemente contenidos de Internet, como páginas HTML, imágenes y videos. Las CDN son extremadamente populares y sirven a la mayoría del tráfico web. Se espera que las CDN entreguen el 72% del tráfico de Internet para 2022 [1], [2], y se prevé que el valor del mercado de las CDN aumente de 11.76 mil millones de dólares en 2019 a 49.61 mil millones de dólares en 2025 [3].

**Una CDN también está sujeta a ataques de seguridad, como la denegación de servicio, que afectan a los servicios de CDN** y la experiencia del usuario final [4], [5]. Proteger las CDN contra ataques de seguridad es críticamente importante porque estos ataques pueden hacer que una CDN funcione mal y reciba cobertura mediática negativa [6]–[9], lo que puede disminuir la reputación del proveedor de CDN resultando en pérdidas significativas de ingresos. Una CDN debe proteger el contenido del robo y la pérdida, mientras preserva la disponibilidad del contenido mitigando los ataques de seguridad.

Desafortunadamente, los adversarios no solo comprometen la protección de la CDN, sino que también utilizan sus infraestructuras para atacar a los usuarios finales y a los sitios web que utilizan servicios de CDN. Por ejemplo, los adversarios engañan los mecanismos de caché de la CDN para generar altos volúmenes de tráfico contra estos sitios web [10]. Incluso explotan una CDN para almacenar en caché públicamente información sensible de los usuarios finales y luego robar esta información de las cachés de la CDN [11].

Considerando el papel crítico de las CDN en la entrega de contenido, proporcionar una comprensión del estado de la seguridad de las CDN es esencial. En este documento, proporcionamos una encuesta exhaustiva sobre los desafíos de seguridad que enfrentan las CDN, junto con sus enfoques de detección y mitigación de ataques. Las principales contribuciones de esta encuesta son:
- Desafíos de seguridad de la CDN: Discutimos las vulnerabilidades de seguridad que enfrenta una CDN. Categorizamos los desafíos de seguridad de la CDN basados en los componentes de la infraestructura de la CDN.
- Contramedidas de la CDN: Discutimos enfoques potenciales de detección y mitigación para contrarrestar los desafíos de seguridad de la CDN. Cubrimos enfoques académicos y comerciales y argumentamos su efectividad y limitaciones.
- Direcciones de investigación: Discutimos oportunidades para mejorar la seguridad de la CDN, así como desafíos de seguridad que enfrentan las CDN futuras. Específicamente, describimos los desafíos de investigación debido al contenido generado por los usuarios y discutimos oportunidades utilizando seguridad definida por software y seguridad colaborativa entre las partes involucradas en la entrega de contenido.

Hasta donde sabemos, esta encuesta es la primera en centrarse en la seguridad de las CDN. Otras encuestas en la literatura se centran en la arquitectura e infraestructura de las CDN [12]–[16], colaboración en la entrega de contenido [17], [18], rendimiento de la CDN [19], [20], y algoritmos operativos de la CDN [21], [22]. Estas encuestas son ajenas a los desafíos de seguridad inherentes en las CDN.

Procedemos de la siguiente manera. En la Sección II, describimos la infraestructura de la CDN y el proceso de entrega de contenido, y categorizamos los desafíos de seguridad de la CDN. Esta categorización facilita la discusión de los desafíos de seguridad en las secciones subsiguientes. Las Secciones III, IV y V están dedicadas a los desafíos de seguridad en cada componente de la CDN, es decir, el servidor periférico, el enrutamiento de solicitudes y el servidor de origen, respectivamente. Finalmente, destacamos las vulnerabilidades actuales, discutimos oportunidades y direcciones de investigación futura en la Sección VI, y concluimos esta encuesta en la Sección VII.


# II. REDES DE ENTREGA DE CONTENIDO: UNA INTRODUCCIÓN

Una CDN tiene como objetivo mejorar la calidad de experiencia en la entrega de contenidos digitales a los usuarios finales, mientras utiliza los recursos de la red de manera más eficiente. Una CDN almacena contenidos en ubicaciones cercanas a los usuarios finales, enruta las solicitudes de contenido a estas ubicaciones y transfiere los contenidos a los usuarios finales [13], [23], [24].

Los proveedores de CDN, los propietarios de contenido y los usuarios finales son las principales partes involucradas en el proceso de entrega de contenido. **Un proveedor de CDN gestiona y opera la infraestructura de CDN. Un propietario de contenido posee contenidos digitales y es cliente de una CDN. Los propietarios de contenido delegan la entrega de sus contenidos a las CDN. Un usuario final consume contenido utilizando sus dispositivos digitales, como televisores, tabletas y teléfonos inteligentes.**


## A. Visión general del proceso de entrega de contenido
Un propietario de contenido coloca contenidos digitales en servidores de origen. La CDN distribuye y replica contenido desde servidores de origen a numerosos servidores periféricos (por ejemplo, cientos a miles de servidores). Estos servidores periféricos están distribuidos a través de Internet para proporcionar una capacidad de almacenamiento de alta capacidad para almacenar contenidos en la cercanía de los usuarios finales [25].
![[Pasted image 20240505205928.png]]
La Figura 1 muestra la entrega de contenido a través de una CDN. Una CDN recibe y atiende las solicitudes de los usuarios finales en nombre de los propietarios de contenido distantes (paso 1). Utilizando un mecanismo de enrutamiento de solicitudes, la CDN selecciona y redirige una solicitud legítima a uno de sus servidores periféricos (paso 2). El servidor periférico seleccionado realiza un control de admisión, y si la solicitud es aceptada, el servidor entrega el contenido desde su caché (paso 3) [26]. En caso de fallos de caché, un servidor periférico recupera y almacena el contenido de otro servidor periférico o de un servidor de origen (paso 4).


## B. Infraestructura de la Red de Entrega de Contenidos
Todos los componentes de la CDN, incluidos los servidores periféricos, el enrutamiento de solicitudes y los servidores de origen, están involucrados en la entrega de contenido [25], [27], [28]. A continuación, discutimos cada componente con más detalle.

### 1. Servidores periféricos
**Los servidores periféricos actúan como un escudo protector para almacenar contenidos y reducir la carga en los servidores de origen**. Los servidores periféricos están estratégicamente ubicados en los puntos de presencia de la CDN, en el borde cercano a los usuarios finales, por ejemplo, a uno o dos saltos de distancia. Los puntos de intercambio de Internet, las redes de proveedores de servicios de Internet y los centros de datos son ejemplos de puntos de presencia. Un punto de presencia puede contener varios servidores periféricos.

Los servidores periféricos también pueden cooperar sirviendo las solicitudes de contenido de otros [26]. Esta colaboración crea una segunda capa de caché, ya que el servidor periférico posterior almacena respuestas de los servidores de origen. Además, los servidores periféricos utilizan una caché jerárquica basada en la popularidad. Almacenan contenidos populares en memoria, mientras que otros se mantienen en discos [29], [30]. Un algoritmo de reemplazo (por ejemplo, el menos recientemente usado o el menos frecuentemente usado) gestiona los contenidos que permanecen en la caché [31].

Existen tres modelos principales para distribuir contenidos desde servidores de origen a servidores periféricos [13], [22], [28], [32]. Primero, un modelo de empuje distribuye contenido si se anticipa su solicitud en un servidor periférico [33], [34]. Segundo, en un modelo de extracción, un servidor periférico obtiene contenidos tras recibir solicitudes de usuarios finales [35], [36]. Finalmente, un modelo híbrido de empuje-extracción se adapta dinámicamente a las solicitudes cambiantes de los usuarios finales empujando algunos contenidos de manera proactiva y extrayendo otros de manera reactiva [37].

Los servidores periféricos ejecutan proxies de caché web para implementar la caché. Los proxies de caché pueden almacenar fácilmente contenidos estáticos para atender futuras solicitudes, porque los contenidos estáticos no cambian con el tiempo. En contraste, la caché de contenidos dinámicos es más complicada. Por ejemplo, Edge Side Includes [38] es un lenguaje de marcado para especificar partes dinámicas de un contenido web, permitiendo a un proxy de caché recuperar solo partes dinámicas (por ejemplo, las últimas noticias en una página web de una empresa) mientras almacena en caché partes estáticas (por ejemplo, la imagen de la marca de una empresa). Los servidores periféricos también pueden ejecutar scripts para generar un conjunto de contenidos dinámicos basados en eventos y entradas, como la hora del día, los tipos de dispositivos y las ubicaciones de los usuarios finales.

### 2. Enrutamiento de solicitudes
El componente de enrutamiento de solicitudes monitorea la condición de la red, la carga en los servidores periféricos y distribuye las solicitudes entre los servidores periféricos basándose en los datos monitoreados [25], [32], [39]–[41]. El enrutamiento de una solicitud se basa en una variedad de métricas, como la proximidad a los usuarios finales, la distancia lógica (por ejemplo, el número de saltos), la latencia, la fluctuación y la carga del servidor [27].

Las técnicas de enrutamiento de solicitudes se clasifican principalmente en enrutamiento basado en el sistema de nombres de dominio (DNS), enrutamiento anycast, enrutamiento a nivel de aplicación y combinaciones de estos [40], [42]. El enrutamiento de solicitudes basado en DNS utiliza los servicios de DNS ubicuos existentes. Las CDN comúnmente ejecutan sus propios servidores de nombres y mantienen registros DNS dinámicos para equilibrar la carga entre los servidores periféricos [42]–[44].

Con el enrutamiento basado en DNS, un usuario final envía una solicitud DNS para el nombre de dominio de un contenido (por ejemplo, 'youtube.com') a su servidor de nombres local. Este servidor de nombres reenvía la solicitud al servidor de nombres autoritativo de la CDN, que responde con la dirección IP de un servidor periférico. Los servidores de nombres autoritativos de la CDN también realizan balanceo de carga, es decir, resuelven solicitudes para el mismo nombre de dominio a las direcciones IP de diferentes servidores periféricos.

Anycast simplifica el enrutamiento de solicitudes al delegar el enrutamiento a Internet. En el enrutamiento anycast, el servidor de nombres autoritativo de la CDN también devuelve una dirección IP. La diferencia con el enrutamiento basado en DNS es que múltiples servidores periféricos utilizan la misma dirección IP, y el protocolo de gateway de borde (BGP) enruta una solicitud al servidor periférico más cercano. Específicamente, múltiples servidores periféricos en una ubicación geográfica particular anuncian la misma dirección IP, y BGP selecciona el camino más corto del sistema autónomo para alcanzar el servidor periférico más cercano.

Por ejemplo, Open Connect [45], la CDN de Netflix, utiliza enrutamiento BGP. Open Connect contiene un conjunto de servidores periféricos físicos especialmente diseñados, llamados Open Connect Appliances (OCAs) para entregar contenidos de video. Open Connect despliega OCAs en redes ISP y puntos de intercambio de Internet, y utiliza el Discriminador de Salida Múltiple (MED) para priorizar OCAs sobre rutas BGP alternativas. Esto permite que Netflix localice su tráfico lo más cerca posible de sus usuarios finales, minimizando las distancias de red y geográficas para la entrega de contenido.

El enrutamiento de solicitudes a nivel de la capa de aplicación se basa en el protocolo HTTP y puede enrutar solicitudes en la granularidad de los objetos de contenido. Mediante la reescritura de URL, las URL de los sitios web se sustituyen por subdominios de CDN que se resuelven a servidores periféricos de CDN. Por ejemplo, el propietario de un nombre de dominio "www.great.com" publica contenidos asociados con "www.great.com.cdn.net" perteneciente a una CDN.

Las CDN pueden combinar las técnicas anteriores para mejorar la precisión y el rendimiento del enrutamiento de solicitudes. Por ejemplo, YouTube [46], Google [47], Akamai [48] y Microsoft utilizan redirección basada en DNS y a nivel de aplicación. Bing y LinkedIn combinan enrutamiento basado en DNS y anycast [49], [50].

### Servidores de origen
Los servidores de origen alojan contenidos originales, por ejemplo, páginas web de un sitio web. Un servidor de origen es gestionado por un propietario de contenido o un proveedor de CDN [25], [51]. Un propietario de contenido puede ubicar los contenidos en el sitio o en la nube [52]. NOKIA Velocix [51] es una CDN que opera servidores de origen optimizados para transmisión, descarga y almacenamiento en caché.

Los servidores de origen normalmente ejecutan servidores web, por ejemplo, NGINX y Microsoft IIS, para alojar y servir contenidos web. Incluso utilizando servicios de CDN, los servidores de origen todavía atienden la mayoría de las solicitudes de contenidos web dinámicos (por ejemplo, redes sociales en línea y páginas web personales). Esto se debe a que los contenidos dinámicos se generan por solicitud y basados en datos que un propietario de contenido no puede compartir con una CDN (por ejemplo, información del usuario final).

## C. Comparación con Redes Centradas en la Información
La Red Centrada en la Información (ICN) [53] cambia la red de una comunicación punto a punto a un paradigma centrado en el contenido. En este paradigma, los nodos de la red (por ejemplo, routers) almacenan contenidos usando sus nombres. Además, la red proporciona dos primitivas, similares a las de un sistema de publicación/suscripción. Un propietario de contenido utiliza una primitiva de 'publicación' para hacer disponibles los contenidos, y un usuario final solicita contenidos utilizando una primitiva de 'suscripción' [53].

Las ICN y las CDN provienen de paradigmas de red diferentes, aunque tienen similitudes en el almacenamiento en caché de contenidos. El paradigma de ICN elimina las direcciones de contenido, donde los contenidos se publican y se suscriben solo por nombre. Además, los nodos de la red almacenan y entregan contenidos en lugar de servidores periféricos. Consumir un contenido ya no es una conexión de extremo a extremo con un servidor (por ejemplo, ‘cdn.youtube.com/best-video-ever’), sino más bien la entrega de un contenido nombrado (por ejemplo, ‘best-video-ever’).

Las ICN enfrentan desafíos de seguridad únicos relevantes para los contenidos en lugar de los canales de comunicación, y estos desafíos no son necesariamente aplicables a las CDN [54]. Por ejemplo, almacenar contenidos en nodos de red hace que una ICN sea vulnerable a anuncios falsos y ataques de análisis de tiempo [54]. Utilizando anuncios falsos, un adversario puede anunciar muchas actualizaciones de contenido que llevan a un estado de contenido erróneo. El análisis de tiempo permite a un adversario violar la privacidad de los usuarios finales deduciendo sus patrones de solicitud.

## D. Organización de Desafíos de Seguridad
Las CDN son una infraestructura de red masiva a través de Internet con un mercado de miles de millones de dólares [1]–[3]. Esto nos motiva a investigar los desafíos de seguridad de las CDN.
La Figura 2 categoriza los desafíos de seguridad de las CDN, es decir, ataques y vulnerabilidades de seguridad. Categorizamos los desafíos de seguridad por componente de CDN, como se discutió en la Sección II-B.
También usamos una subcategoría similar a la de [55], que son representativas de los ataques conocidos. No afirmamos que nuestra categorización divida exclusivamente los desafíos de seguridad; un desafío de seguridad y sus contramedidas posiblemente sean relevantes para múltiples componentes de CDN.
La Tabla I y la Tabla II facilitan la lectura al listar la terminología y los acrónimos de CDN utilizados en este estudio. En la Tabla I, la primera columna muestra los términos utilizados en todo este estudio, y la segunda columna enumera otros términos equivalentes de la literatura. La Tabla II proporciona las formas expandidas de los acrónimos utilizados en este estudio.


# III. DESAFÍOS DE SEGURIDAD EN SERVIDORES PERIFÉRICOS
En esta sección, revisamos los desafíos de seguridad y las contramedidas relacionadas con los servidores periféricos. Las CDN sirven solicitudes web haciendo que los servidores periféricos sean vulnerables a ataques en la capa de aplicación (cf., Sección III-A). Las CDN también son vulnerables a amenazas de almacenamiento en caché (cf., Sección III-B). Además, los adversarios envían solicitudes maliciosas que explotan vulnerabilidades de los servidores periféricos para lanzar ataques de denegación de servicio (cf., Sección III-C). Los servidores periféricos también son explotados como un canal de comunicación encubierto para transmitir información sensible (cf., Sección III-D).

A. Capa de Aplicación
La mayoría de las CDN sirven tráfico web y almacenan contenidos web en servidores periféricos. Esto hace que los servidores periféricos sean propensos a ataques en la capa de aplicación web [56]–[61].

1) Amenazas prevalentes: Las amenazas de aplicación web incluyen inyección SQL, scripting entre sitios, inclusión de archivos, ejecución de comandos remotos, acceso ilegal a recursos, ataques de diccionario, abuso de ancho de banda, por nombrar algunos. Pueden llevar a diversas implicaciones para las organizaciones víctimas, como fuga de datos (por ejemplo, exfiltración de datos usando inyección SQL y scripting entre sitios), fraude o mal funcionamiento empresarial (por ejemplo, raspado de pantalla, spam y cuentas falsas), y la interrupción debido a denegación de servicio.

El análisis estático o dinámico del código fuente de la aplicación web puede revelar vulnerabilidades de seguridad [62], [63]. Sin embargo, estos análisis no disuaden todas las amenazas posibles. CoDeen [60] emplea la limitación y la inclusión en listas negras de solicitudes particulares para contrarrestar amenazas. Restringe las solicitudes HTTP POST debido a sus riesgos de seguridad inherentes. Sin embargo, esto limita la flexibilidad de una CDN para soportar solicitudes HTTP. CoDeen también impone una mayor restricción en las solicitudes que coinciden con firmas de amenazas específicas. Por ejemplo, prohíbe a un usuario final por un día por realizar intentos de inicio de sesión HTTP frecuentes. Además, CoDeeN incluye en listas negras a usuarios finales que son sospechosos de realizar pruebas de vulnerabilidad y ataques de diccionario.


Los cortafuegos de aplicaciones web (WAF, por sus siglas en inglés) también pueden defender a los servidores periféricos contra ataques comunes a aplicaciones web, ampliamente utilizados por las CDN comerciales [64]–[68]. Los WAF se instalan en o delante de los servidores periféricos. Realizan una inspección profunda de las solicitudes y respuestas web para detectar y bloquear estos ataques [69]. Configuran los WAF para filtrar tráfico basado en las amenazas identificadas por el proyecto de seguridad de aplicaciones web abiertas (OWASP) [70], servicios específicos de CDN, y los requisitos de seguridad de los propietarios de contenido. Por ejemplo, el WAF de Alibaba [65] protege las aplicaciones web contra los diez principales riesgos de seguridad de OWASP [71]. Otros WAF, como el WAF de Incapsula [66], están diseñados para cumplir con estándares, incluyendo el "estándar de seguridad de datos para la industria de tarjetas de pago" o los "estándares de portabilidad y responsabilidad de seguros de salud". La detección de amenazas en la capa de aplicación requiere una inspección profunda de paquetes (DPI, por sus siglas en inglés), lo que conlleva un alto consumo de recursos. Algunas CDN [64], [67], [68] implementan un WAF por servidor periférico, compartiendo los mismos recursos utilizados por los servicios de entrega de contenido. Además, el DPI plantea preocupaciones de privacidad. Si una CDN tiene recursos suficientes para realizar DPI en el tráfico, potencialmente podría vigilar y discriminar el tráfico hacia sus servidores periféricos, lo cual va en contra de la neutralidad de la red. Además, pueden compartir información con empresas de marketing [72]–[74].


2) Oculto en tráfico encriptado: Los atacantes pueden camuflar ataques de capa de aplicación dentro de tráfico encriptado para eludir los mecanismos de seguridad de la CDN y los servidores periféricos, y dirigirse directamente a los servidores de origen [74]. El tráfico encriptado se está convirtiendo en un estándar de facto en el ecosistema de CDN de hoy. Esto se ve exacerbado por la adopción de protocolos web de próxima generación, por ejemplo, HTTP/2. La encriptación del tráfico se logra principalmente a través del protocolo Secure Sockets Layer (SSL)/Transport Layer Security (TLS). Usando SSL/TLS, los usuarios finales establecen una conexión segura de extremo a extremo con los servidores de origen para acceder a contenidos proporcionados por los propietarios de contenido [75]. Sin las claves privadas de los propietarios de contenido, una CDN tiene una capacidad limitada para analizar el tráfico encriptado entre los usuarios finales y los servidores de origen. En este caso, una CDN debe redirigir el tráfico hacia los servidores de origen, sin inspeccionar el contenido del tráfico.

Una CDN aún puede analizar las partes no encriptadas del tráfico encriptado (por ejemplo, la fase de negociación de la comunicación SSL/TLS) y realizar análisis de comportamiento sobre estadísticas de tráfico (por ejemplo, características basadas en flujos) [76]. Los sistemas de detección de intrusiones pueden detectar ataques utilizando estas características estadísticas y aplicar flujos de trabajo de mitigación. Por ejemplo, Amoli y Hamalainen [77] utilizan aprendizaje automático no supervisado en métricas en tiempo real, como número de flujos de red, paquetes y bytes, para detectar escaneos y ataques de denegación de servicio.

La DPI para la detección de amenazas de capa de aplicación implica inspeccionar tráfico desencriptado o encriptado [78]. En ambos escenarios, los propietarios de contenido deben confiar en una CDN y compartir sus claves privadas para habilitar la inspección de tráfico en el borde. Sin embargo, con acceso a las claves privadas, una CDN puede esencialmente convertirse en un hombre en el medio, haciendo que los propietarios de contenido sean vulnerables a espionaje e incluso suplantación de identidad. Discutimos este dilema más adelante en la Sección V-A.

Es difícil para una CDN proporcionar servicios efectivos de entrega de contenido y seguridad al mismo tiempo. Interceptando tráfico para DPI se sacrifica un grado de privacidad y confianza. Aunque existen enfoques, como la encriptación homomórfica completa o la encriptación funcional [79], [80] que permiten la inspección de tráfico encriptado sin desencriptación, son imprácticos debido a su bajo rendimiento prohibitivo. De hecho, es un desafío para una CDN proporcionar servicios de seguridad efectivos, mientras se preserva la privacidad de los propietarios de contenido y los usuarios finales.

B. Amenazas de almacenamiento en caché

La popularidad del contenido es una característica importante que permite su reemplazo eficiente en servidores periféricos. La popularidad del contenido sigue una distribución de Zipf con cola larga, de tal manera que hay un pequeño conjunto de contenidos populares, mientras que la mayoría de los contenidos raramente se solicitan [22], [55]. Los servidores periféricos almacenan contenido popular para aprovechar el principio de referencia de localidad, es decir, un contenido solicitado recientemente es probable que se solicite nuevamente. Los atacantes apuntan al principio de localidad de referencia para degradar el rendimiento de almacenamiento en caché con contenido impopular [81], [82]. También atacan la integridad de la caché de los servidores periféricos mediante envenenamiento de caché que reemplaza una respuesta en caché legítima con un contenido falsificado. Hasta que expire la caché, las solicitudes posteriores para el mismo contenido recibirán el contenido falsificado en lugar del original [83]. Utilizando técnicas similares al envenenamiento de caché, los adversarios roban información sensible engañando a los servidores periféricos para que almacenen información del usuario final [11], [84]–[86].

1) Contaminación de la caché: Los servidores periféricos son vulnerables a la contaminación de la caché [10], [87], lo que resulta en un servicio de caché degradado con fallos de caché frecuentes. Para contaminar exitosamente la caché de un servidor periférico, un atacante debe generar solicitudes para contenidos impopulares, que sean comparables en número a las solicitudes de usuarios finales legítimos para contenidos populares. Estos ataques pueden deteriorar el rendimiento general de la red sin saturarla, afectando a usuarios finales legítimos y servidores periféricos. Además, la detección de la contaminación de la caché es desafiante, porque los contenidos impopulares que ocupan la caché son inherentemente no maliciosos.

Los atacantes apuntan a la localidad de la caché para degradar la calidad del servicio (QoS) de la CDN. La localidad se refiere a la tendencia de un servidor periférico a servir el mismo contenido. Una alta localidad permite que un servidor periférico almacene contenidos populares y sirva varias solicitudes para el mismo contenido desde su caché local.

Los atacantes afectan la localidad de la caché utilizando dos enfoques. Primero, utilizando una estrategia de falsa localidad, un atacante genera continuamente solicitudes para el mismo conjunto de contenidos impopulares, lo que deteriora la proporción de aciertos de la caché para contenidos populares. Estos ataques pueden repoblar rápidamente la caché con contenidos impopulares. Segundo, un atacante solicita frecuentemente un nuevo conjunto de contenidos impopulares, degradando consecuentemente la eficiencia de la caché e impactando a los usuarios finales legítimos.

Los ataques de contaminación de la caché implican patrones de acceso a contenidos que son marcadamente diferentes a las solicitudes legítimas. Por lo tanto, las contramedidas se aprovechan de las métricas que capturan esta diferencia y realizan análisis basados en umbrales para contrarrestar estos ataques.

En un ataque de falsa localidad, los usuarios finales maliciosos solicitan los mismos contenidos impopulares con frecuencia, mientras que un usuario final legítimo rara vez solicita el mismo contenido repetidamente en un corto período de tiempo [88]. Esta diferencia ha sido aprovechada para desarrollar dos enfoques de detección, a saber, detección basada en el atacante y detección basada en el objeto. En la detección basada en el atacante, si el número y porcentaje de solicitudes repetidas superan los umbrales predefinidos, el usuario final se clasifica como malicioso. En la detección basada en el objeto, si el número de solicitudes para un contenido es relativamente mayor comparado con el número de usuarios finales que lo solicitan, el contenido se considera un contenido popular falso y se elimina de la caché. Todos estos enfoques de mitigación requieren ajustar umbrales de detección apropiados. Sin embargo, encontrar valores de umbral no es trivial.

Manivel et al. [89] detectan usuarios finales maliciosos rastreando su historia reciente de aciertos y fallos de caché. Para rastrear las actividades de los usuarios finales, se mantiene un mapeo entre los usuarios finales y sus solicitudes de contenido. Si la proporción de aciertos de caché reciente de un usuario final está por debajo de un umbral predefinido, el usuario final se clasifica como atacante. Este enfoque se centra en el comportamiento reciente de un usuario final y evita una clasificación permanente. De hecho, un usuario final con poca localidad puede tener una baja proporción de aciertos, aunque sea legítimo. Por lo tanto, con una clasificación que cambia con el tiempo, un usuario final solo está sujeto a una clasificación errónea temporal.

Park et al. [90] consideran la aleatoriedad de las solicitudes para identificar un ataque de disrupción de la localidad, es decir, cuanto menor es la aleatoriedad, mayor es la probabilidad de disrupción de la localidad. Este enfoque mantiene una matriz de estadísticas de solicitudes. Se detecta un ataque si la entropía de la matriz cae por debajo de un umbral predefinido.

En contraste, Dang et al. [88] proponen un enfoque de dos pasos para detectar tanto la falsa localidad como los ataques de disrupción de localidad. En primer lugar, los autores utilizan enfoques de detección basados en el atacante o en el objeto para detectar la falsa localidad. Esto permite excluir los contenidos impopulares del paso siguiente. En segundo lugar, los ataques de disrupción de localidad se detectan por separado utilizando la métrica de tiempo de vida promedio periódico.

2) Envenenamiento de caché: Kettle [91] descubre un ataque que hace un mal uso de los "entradas no claveadas" y el concepto de "claves de caché" para envenenar las cachés web en servidores periféricos.

Los proxies web utilizan almacenes de valores clave para rastrear sus cachés. Para asociar una solicitud HTTP con respuestas en caché, combinan los valores de ciertas cabeceras HTTP (por ejemplo, HOST y GET) en la solicitud, como una clave de caché. Sin embargo, los proxies web excluyen algunas cabeceras HTTP (por ejemplo, User-Agent y Cookie) de las claves de caché, ya que pueden ser muy específicas para una solicitud particular, haciéndolas imprácticas para el almacenamiento en caché. Estas se denominan entradas no claveadas, las cuales son susceptibles al envenenamiento de la caché web.

Un adversario puede crear una solicitud HTTP con valores arbitrarios (potencialmente maliciosos) para estas cabeceras, mientras que la clave de caché de la solicitud sigue siendo lo suficientemente general como para coincidir con futuras solicitudes. La Figura 3 ilustra un ataque de envenenamiento de caché. Primero, un adversario crea y envía una solicitud HTTP, incluyendo valores dañinos para las entradas no claveadas (por ejemplo, X-Host: badguy.com). Segundo, un servidor periférico reenvía esta solicitud a un servidor de origen. Tercero, el servidor de origen responde con una respuesta envenenada que incluye los valores dañinos de la solicitud HTTP. Específicamente, los servidores web de origen pueden incluir algunos valores de las cabeceras de las solicitudes HTTP en sus respuestas. Un servidor web de origen genera una respuesta envenenada que incluye los valores dañinos de las entradas no claveadas (por ejemplo, una página HTML que incluye <script src="badguy.com/foo.js"></script>).

Cuarto, el servidor periférico almacena esta respuesta para solicitudes HTTP legítimas. Quinto, un usuario final envía una solicitud que se mapea con el registro de caché envenenado. Finalmente, el servidor periférico responde con una respuesta de su caché envenenada.

Este ataque puede ser mitigado en los servidores de origen y periféricos. Los servidores de origen pueden prevenirlo excluyendo los valores de las cabeceras HTTP en las respuestas. Sin embargo, esto limita la flexibilidad de las aplicaciones web que hacen uso de las cabeceras HTTP. Los servidores periféricos pueden aliviar el impacto de este ataque incluyendo más cabeceras HTTP en las claves de caché. Por ejemplo, Cloudflare incluye más cabeceras HTTP, como X-Host, X-Forwarded-Host y X-Forwarded-Scheme, como parte de sus claves de caché [92]. Sin embargo, esto puede impactar el rendimiento de la caché, ya que incluir más cabeceras HTTP aumenta el espacio de clave de caché.

3) Engaño de caché web: Este ataque tiene como objetivo robar información sensible del usuario final. Un atacante engaña a un usuario final para que solicite un contenido dinámico que contenga información sensible (por ejemplo, los detalles de una cuenta de pago privada), que se sirve desde el servidor de origen y se almacena en caché en un servidor periférico. El atacante luego accede a esta información directamente desde la caché del servidor periférico [11], [84]–[86]. Akamai, Cloudflare, CloudFront y Fastly fueron reportados como vulnerables a este ataque [11].

Este ataque involucró cinco pasos. Primero, un adversario engaña a un usuario final para que solicite una URL inexistente que termina con un contenido estático, como 'http://www.bank.com/profile/foo.jpg' (es decir, 'foo.jpg' es un contenido estático inexistente). Segundo, un servidor periférico recibe y redirige esta solicitud a un servidor de origen. Tercero, el servidor de origen genera y responde con un contenido dinámico de la siguiente manera. El servidor web en el origen puede estar configurado para ser flexible en el servicio de diferentes rutas y sirve esta URL inexistente invocando un script ubicado en 'http://www.bank.com/profile'. El script genera contenidos dinámicos con información sensible del usuario final (por ejemplo, la información del perfil del usuario final). Cuarto, el servidor periférico almacena la respuesta, porque la solicitud aparentemente es para un contenido estático (por ejemplo, una imagen 'jpg'). Quinto, el adversario puede entonces solicitar la misma URL, y el servidor periférico responde con el contenido en caché.

Para superar este ataque, los servidores de origen pueden configurarse para responder adecuadamente a URLs inesperadas o forzar a los servidores periféricos a excluir contenidos sensibles de la caché [86]. Por ejemplo, un servidor web de origen responde con HTTP 404 para URLs inexistentes. Un servidor de origen también puede configurar el encabezado Cache-Control a No-Cache, asegurando que el servidor periférico no almacene en caché respuestas con información sensible. Los servidores periféricos también pueden evitar almacenar en caché contenidos sensibles, haciendo coincidir el tipo de respuesta con las URLs solicitadas. Por ejemplo, un servidor periférico no debería almacenar en caché una respuesta HTML para una solicitud de imagen con una extensión 'jpg' [85], [93].

C. Denegación de Servicio

En un ataque de denegación de servicio, los adversarios tienen como objetivo evitar que los usuarios finales legítimos accedan a los servicios de CDN [94]. Un ataque de denegación de servicio distribuido emplea múltiples entidades atacantes para lograr el mismo objetivo. Por ejemplo, un adversario puede inundar un servidor periférico, consumir sus recursos y evitar que los usuarios finales legítimos accedan a los contenidos. Estos ataques interrumpen los servicios de CDN, causando que los negocios de CDN pierdan ingresos considerables.

Aprovechando la vulnerabilidad de los servidores periféricos en servir contenidos dinámicos, los adversarios utilizan una CDN para amplificar sus ataques de denegación de servicio contra servidores de origen [10]. Además, explotan vulnerabilidades de los encabezados de solicitudes HTTP para almacenar en caché contenidos envenenados en servidores periféricos, haciendo que los contenidos originales no estén disponibles para los usuarios finales legítimos [95]–[97].

1) Denegación de servicio por cadena aleatoria: Típicamente, los servidores periféricos reenvían las solicitudes de contenidos dinámicos a los servidores de origen, ya que servir estas solicitudes desde la caché local no es trivial. Sin embargo, el reenvío de estas solicitudes a los servidores de origen introduce una vulnerabilidad que los atacantes pueden explotar para lanzar ataques de amplificación de denegación de servicio.

Triukose et al. [10] crean URLs con cadenas aleatorias para inundar los servidores de origen y consumir los recursos de una CDN. Añadir una cadena aleatoria a una URL de solicitud de usuario (por ejemplo, añadiendo ‘?q=rand’ a ‘http://www.domain.com/image.jpg’) provoca un fallo de caché en el servidor periférico, incluso cuando la cadena añadida podría no corresponder a contenidos dinámicos reales. En consecuencia, a través de dos conexiones TCP desacopladas, el servidor periférico recupera y entrega el contenido perdido (por ejemplo, ‘image.jpg’) desde el servidor de origen.

El contenido se recupera de un servidor de origen al servidor periférico sobre la primera conexión, mientras que el contenido se entrega desde el servidor periférico al atacante sobre la segunda conexión. La primera conexión tiene un alto rendimiento, mientras que el rendimiento de la segunda conexión es bajo (es decir, ajustado a la conexión del atacante). Dado que el ataque consume un orden de magnitud más ancho de banda en la conexión del servidor de origen, el atacante puede forzar a los servidores periféricos a amplificar el tráfico hacia los servidores de origen. Aunque el objetivo principal de este ataque son los servidores de origen, un atacante también puede contaminar las cachés y reducir el rendimiento de los servidores periféricos.

Triukose et al. [10] exploran una lista de técnicas de mitigación. En una defensa "sin compromisos", un contenido dinámico se sirve solo por servidores de origen, mientras que los servidores periféricos solo sirven contenidos estáticos. En este caso, las solicitudes de contenidos dinámicos pueden ser descartadas por los servidores periféricos o por los servidores de origen (es decir, solicitudes de contenidos dinámicos reenviadas por un servidor periférico). Sin embargo, esto disminuye la efectividad y flexibilidad de una CDN para servir solicitudes dinámicas.

Los servidores periféricos y los servidores de origen también pueden colaborar para servir contenido dinámico. Los servidores periféricos añaden cierta información (por ejemplo, direcciones IP de los usuarios finales) a las solicitudes que se reenvían a los servidores de origen. Los servidores de origen pueden aprovechar esta información para la detección y mitigación de amenazas. Por ejemplo, los servidores de origen pueden limitar la tasa de solicitudes procedentes de la misma dirección IP. Este enfoque es efectivo si la CDN también gestiona los servidores de origen. De lo contrario, los propietarios de contenido deben proteger sus servidores de origen contra el ataque de cadena aleatoria, sin suficiente apoyo de la CDN. Alternativamente, una CDN puede aprovechar mecanismos de detección de anomalías para detectar una tasa anormal de solicitudes a los servidores de origen. Sin embargo, esto conlleva un alto costo de rendimiento.

El factor de amplificación del ataque depende de la diferencia de rendimiento entre las dos conexiones TCP. Por lo tanto, controlar el rendimiento de estas conexiones puede disminuir el impacto de un ataque de amplificación. Una CDN puede aplicar limitación de conexión, donde la transferencia de contenido entre servidores de origen y servidores periféricos se ralentiza, basada en el progreso de la entrega entre un servidor periférico y un usuario final. La CDN también puede aprovechar la interrupción del reenvío para detener la transferencia de contenidos entre un servidor de origen y un servidor periférico, tan pronto como un usuario final cierra su conexión.


2) Denegación de servicio por envenenamiento de caché: Mediante un ataque de envenenamiento de caché web, los adversarios pueden hacer que un servidor periférico almacene y sirva páginas de error en lugar de los contenidos originales [95]–[97]. Esto hace que los contenidos no estén disponibles para las próximas solicitudes legítimas. Akamai, Azure, CDN77, Cloudflare, CloudFront y Fastly fueron reportados como vulnerables a este ataque [95].

El ataque de envenenamiento de caché tiene cuatro pasos. Primero, un adversario crea y envía una solicitud HTTP incluyendo una cabecera maliciosa que apunta a un contenido víctima. Segundo, un servidor periférico reenvía la solicitud a un servidor de origen, mientras la cabecera maliciosa permanece sin detectar en el servidor periférico. Tercero, el procesamiento de la cabecera maliciosa en el servidor de origen provoca un error, y el servidor de origen genera y responde con una página de error al servidor periférico. Cuarto, el servidor periférico almacena esta página de error en lugar del contenido original. El servidor periférico responde con esta página de error a solicitudes recurrentes para el contenido víctima.

Hay tres cabeceras en las solicitudes HTTP que pueden ser explotadas para este ataque [95], [96]. Utilizando una cabecera HTTP de tamaño excesivo, un adversario crea una cabecera de solicitud que, aunque es admitida por un servidor periférico, es demasiado grande para que el servidor de origen la maneje debido a su configuración.

Usando metacaracteres HTTP, un adversario crea una cabecera de solicitud con un metacarácter dañino, por ejemplo, \n, \r, y \a. Un servidor periférico reenvía esta solicitud a un servidor de origen, donde el metacarácter causa un error.

Utilizando la anulación del método HTTP, un adversario crea solicitudes PUT y DELETE para eludir los servidores periféricos y provocar un error en un servidor de origen. Los proxies web y los cortafuegos en los servidores periféricos comúnmente solo admiten los métodos HTTP GET y POST, y bloquean las solicitudes con DELETE y PUT. Algunos marcos web en los servidores de origen, por ejemplo, Play Framework 1, sortean esta limitación admitiendo cabeceras de anulación, como X-HTTP-Method-Override. Estas cabeceras permiten el túnel de métodos HTTP bloqueados. En un servidor de origen, el marco web reemplaza el método HTTP de una solicitud con el valor de la cabecera de anulación. Para llevar a cabo este ataque, un adversario envía una solicitud GET con una cabecera X-HTTP-Method-Override configurada para POST. Un servidor periférico interpreta esta solicitud como un GET benigno, mientras que un servidor de origen la interpreta como un POST después de anular el método HTTP. Si la lógica de la aplicación web no implementa POST para el contenido solicitado, el servidor de origen devuelve el mensaje de error HTTP 404. Basado en RFC 7231 [98], el servidor periférico tiene permitido almacenar esta página de error para servir solicitudes recurrentes.

Excluir las páginas de error de la caché puede prevenir completamente este ataque. Sin embargo, esto puede afectar el rendimiento y la escalabilidad de las CDN. Un servidor de origen también puede generar mensajes de respuesta con Cache-Control: no-store, y los servidores periféricos deben respetar esta cabecera. Otra aproximación es deshabilitar el almacenamiento en caché en los servidores periféricos. Akamai, CDN77, CloudFront y Fastly pueden configurarse con esta opción.

Los WAFs desplegados frente a los proxies web en los servidores periféricos también pueden filtrar cabeceras de solicitud maliciosas. Sin embargo, los WAFs frente a los servidores de origen no mitigan este ataque, ya que aún pueden generar páginas de error que serán almacenadas en caché en los servidores periféricos. Además, el DPI en los WAFs también puede afectar el rendimiento de la CDN.

Los canales encubiertos permiten a los adversarios comunicar información, mientras la comunicación permanece indetectada. Esto les permite a los adversarios eludir los mecanismos de seguridad y utilizar un CDN como medio para transmitir y robar información sensible [100].
La infraestructura de CDN puede ser utilizada como un canal encubierto. El acceso público a los servicios de CDN permite a los adversarios reclutar y explotar la comunicación entre los servidores de borde y los servidores de origen para codificar y transmitir mensajes secretos.
El canal encubierto de CDN: Wang et al. [99] explotan los servidores de borde y los servidores de origen de CDN para crear un canal de comunicación encubierto entre usuarios finales maliciosos y un propietario de contenido malicioso que utiliza los servicios de CDN. Como prueba de concepto, los autores llevan a cabo el ataque en CloudFront.
La Figura 4 ilustra el desarrollo del canal encubierto de CDN en cinco pasos. Primero, un usuario final malicioso o un propietario de contenido malicioso recopila las direcciones IP de los servidores de borde. Segundo, el usuario final malicioso o el propietario de contenido malicioso idean un esquema de codificación de información. Tercero, las direcciones IP recopiladas y el esquema de codificación se transmiten a los usuarios finales maliciosos y al propietario de contenido malicioso. Cuarto, el usuario final malicioso selecciona un servidor de borde y codifica un mensaje secreto en una serie de solicitudes de penetración, es decir, solicitudes de contenido que obligan a un servidor de borde a obtener del servidor de origen (por ejemplo, URL 'http://malicious.org?q=dnar' que termina con una cadena aleatoria dnar [10]). Finalmente, el servidor de origen malicioso recibe y decodifica las solicitudes para reconstruir los mensajes.
El esquema de codificación de información utilizado para codificar y decodificar mensajes se basa en el servidor de borde emisor. Por ejemplo, como se muestra en la Figura 4, la misma solicitud recibida de los servidores de borde 1 y 2 se decodifican respectivamente en las letras i y j en el servidor de origen malicioso.
El esquema de información utilizado en los quinto y sexto pasos requiere que el servidor de origen malicioso reciba una solicitud de penetración del mismo servidor de borde que recibe la solicitud del usuario final malicioso. Sin embargo, esto puede no ser siempre el caso, ya que una solicitud puede pasar por múltiples servidores de borde antes de llegar al servidor de origen. Por ejemplo, un servidor de borde A que recibe una solicitud de usuario final (es decir, primer servidor de borde de salto) puede reenviar la solicitud al servidor de borde B que la reenvía al servidor de borde C (es decir, último servidor de borde de salto), desde el cual el servidor de origen recibe la solicitud.
Además, en algunos CDNs (por ejemplo, CloudFront y CoralCDN), un servidor de borde A, en la mayoría de los casos, reenviará una solicitud no almacenada en caché a un servidor de borde B. Este reenvío estático entre servidores de borde en una falta de caché, permite a un atacante idear un mapeo estable entre el primer y el último servidor de borde de salto enviando y rastreando solicitudes únicas.
Un ataque de comunicación exitoso a través de un canal encubierto requiere lo siguiente. Primero, un usuario final malicioso es capaz de seleccionar y enviar una solicitud de penetración a un servidor de borde. Segundo, la solicitud de penetración evita el caché del servidor de borde. Tercero, un usuario final malicioso es capaz de inferir el mapeo entre el primer y el último servidor de borde de salto.
Si alguno de los requisitos anteriores falla, el ataque no tiene éxito [10]. Para negar el primer requisito, un servidor de borde acepta solo solicitudes certificadas. Por lo tanto, un usuario final debe contactar primero a un servidor intermedio para recibir un token de certificado y la dirección IP del servidor de borde seleccionado. El servidor intermedio también envía el certificado al servidor de borde seleccionado. El usuario final debe proporcionar el token con una solicitud al servidor de borde, que solo sirve una solicitud con un token autorizado. Por lo tanto, los usuarios finales no pueden conectarse a servidores de borde arbitrarios. Sin embargo, esto aumenta la latencia de servicio de solicitudes e introduce un sobrecosto de generación y validación de tokens.
Para abordar el segundo requisito, las cadenas de consulta en las solicitudes HTTP pueden ser desactivadas. Esto evita que los servidores de borde reenvíen solicitudes dinámicas a los servidores de origen, evitando así el bypass de los servidores de borde. Esto también evita que un CDN almacene contenido dinámico en sus servidores de borde.
De manera similar, para frustrar el tercer requisito, un CDN puede aleatorizar el mapeo entre los primeros y últimos servidores de borde de salto. Esto socava el esquema de codificación de información para el canal encubierto, ya que el mapeo entre el servidor de borde emisor y las letras ya no es estable.



E. Resumen
La Tabla III resume los desafíos de seguridad y contramedidas discutidos en esta sección. Como se muestra, además de los ataques en la capa de aplicación, los adversarios mayormente apuntan al almacenamiento en caché y rendimiento de los servidores de borde. Esto socava la funcionalidad principal de las CDN para entregar rápidamente y eficientemente contenidos.

Existen problemas abiertos para las CDN para contrarrestar los desafíos de seguridad de los servidores de borde debido a dos razones opuestas. Primero, estos desafíos de seguridad explotan la capa de aplicación, por lo que su detección requiere DPI, lo que conlleva una sobrecarga de rendimiento alta. El crecimiento en la encriptación del tráfico también requiere que las CDN gasten más recursos para DPI. Segundo, inspeccionar el tráfico encriptado plantea preocupaciones de privacidad y confidencialidad. La capa de aplicación contiene información personal identificable (PII), y DPI puede exponer PII de propietarios de contenido y usuarios finales. Desde otra perspectiva, si una CDN posee recursos suficientes para DPI, la CDN también puede vigilar y discriminar el tráfico [72]–[74].

Al inspeccionar el tráfico, las CDN deben cumplir con regulaciones de preservación de la privacidad, como el Reglamento General de Protección de Datos (GDPR) [101] y la Ley de Privacidad del Consumidor de California (CCPA) [102]. Estas regulaciones requieren protecciones de privacidad más estrictas. Otorgan a los consumidores el derecho de controlar qué PII puede ser recopilada, y cómo se utiliza esta información. Para cumplir con estas regulaciones, una CDN debe emplear controles y medidas apropiadas para proteger la privacidad de los usuarios finales y propietarios de contenido. Por ejemplo, DPI no debe exponer las identidades de los usuarios finales, inadvertida o intencionalmente. El incumplimiento puede acarrear serias repercusiones para los proveedores de CDN, incluyendo sanciones financieras y pérdida de reputación.


# VII. CONCLUSIÓN

Las CDN proporcionan una infraestructura para entregar contenidos de Internet a usuarios finales y garantizar la disponibilidad de contenido. Sin embargo, **las CDN son vulnerables a amenazas de seguridad que afectan los servicios de CDN y la experiencia del usuario final**. Los adversarios también pueden utilizar los recursos de la CDN para lanzar ataques más sofisticados contra los usuarios finales y los servidores de origen.

Este documento proporciona una encuesta completa sobre la seguridad de las CDN. Específicamente, categorizamos los desafíos de seguridad de las CDN basados en sus componentes de infraestructura, discutimos enfoques de detección y mitigación de ataques, y presentamos nuestras ideas y direcciones prometedoras para futuras investigaciones. Esperamos que esta encuesta proporcione una mejor comprensión de los desafíos de seguridad de las CDN y allane el camino para futuras investigaciones en esta dirección.